{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba826d8-d3ef-46f4-9609-993455cac6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a7190c-a7ad-4a86-86e6-c91e242006d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_lineplot(fdf,ylst,title='',filename='tmp.png',saveon=False,figsize=(15,10),**kwargs):\n",
    "    # print(title)\n",
    "    ax = fdf.reset_index().plot(x='TIMESTAMP',y = ylst,title=title,figsize=figsize,**kwargs)\n",
    "    ax.grid(True)\n",
    "    return ax\n",
    "def lineplot(fdf,xx,ylst,title='',filename='tmp.png',saveon=False,figsize=(15,10),**kwargs):\n",
    "    # print(title)\n",
    "    ax = fdf.reset_index().plot(x=xx,y = ylst,title=title,figsize=figsize,**kwargs)\n",
    "    ax.grid(True)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165459a5-fa74-4625-9546-7e3cbaaaa6f4",
   "metadata": {},
   "source": [
    "# setting up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5cf66b-e6c5-4868-b2f9-5af02814743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1d1df = pd.read_csv('s1d1df_new_first.csv')\n",
    "s1d1df['TIMESTAMP'] = pd.to_datetime(s1d1df['TIMESTAMP'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "s1d2df = pd.read_csv('s1d2df_new_first.csv')\n",
    "s1d2df['TIMESTAMP'] = pd.to_datetime(s1d2df['TIMESTAMP'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "s1d1df_old = pd.read_csv('s1d1df.csv')\n",
    "s1d1df_old['TIMESTAMP'] = pd.to_datetime(s1d1df_old['TIMESTAMP'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "s1d2df_old = pd.read_csv('s1d2df.csv')\n",
    "s1d2df_old['TIMESTAMP'] = pd.to_datetime(s1d2df_old['TIMESTAMP'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "total_df = pd.DataFrame(columns= ['ping', 'dest_cmu', 'dest_aws', 'hour_of_day', 'day_of_week', 'num_of_hops', 'min_of_day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367aff7b-b63f-4d9e-97c9-fc1dc099ec55",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "for i in range(len(s1d1df)):\n",
    "    for ping_column in ['PING2', 'PING3', 'PING4','PING5', 'PING6', 'PING7', 'PING8', 'PING9', 'PING10']:\n",
    "        new_row = {\n",
    "            'ping': s1d1df.loc[i, ping_column],\n",
    "            'dest_cmu': 1,\n",
    "            'dest_aws': 0,\n",
    "            'TIMESTAMP': int(s1d1df.loc[i, 'TIMESTAMP'].timestamp()),\n",
    "            'min_of_day': (s1d1df.loc[i, 'TIMESTAMP'].hour*60 + s1d1df.loc[i, 'TIMESTAMP'].minute),\n",
    "            'min_of_day_norm': (s1d1df.loc[i, 'TIMESTAMP'].hour*60 + s1d1df.loc[i, 'TIMESTAMP'].minute)/(60*24)*(4*np.pi),\n",
    "            'hour_of_day': s1d1df.loc[i, 'TIMESTAMP'].hour,\n",
    "            'day_of_week': s1d1df.loc[i, 'TIMESTAMP'].dayofweek,\n",
    "            'num_of_hops': s1d1df.loc[i, 'NUM_HOPS']\n",
    "        }\n",
    "        new_rows.append(new_row)\n",
    "new_rows_df = pd.DataFrame(new_rows)\n",
    "new_rows_df['rolling_avg'] = new_rows_df['ping'].rolling(window=1000).mean()\n",
    "total_df = pd.concat([total_df, new_rows_df], ignore_index=True)\n",
    "total_df\n",
    "\n",
    "\"\"\"new_rows = []\n",
    "for i in range(len(s1d1df_old)):\n",
    "    for ping_column in ['PING2', 'PING3', 'PING4','PING5']:\n",
    "        new_row = {\n",
    "            'ping': s1d1df_old.loc[i, ping_column],\n",
    "            'dest_cmu': 1,\n",
    "            'dest_aws': 0,\n",
    "            'TIMESTAMP': int(s1d1df_old.loc[i, 'TIMESTAMP'].timestamp()),\n",
    "            'min_of_day': (s1d1df_old.loc[i, 'TIMESTAMP'].hour*60 + s1d1df_old.loc[i, 'TIMESTAMP'].minute),\n",
    "            'min_of_day_norm': (s1d1df_old.loc[i, 'TIMESTAMP'].hour*60 + s1d1df_old.loc[i, 'TIMESTAMP'].minute)/(60*24)*(4*np.pi),\n",
    "            'hour_of_day': s1d1df_old.loc[i, 'TIMESTAMP'].hour,\n",
    "            'day_of_week': s1d1df_old.loc[i, 'TIMESTAMP'].dayofweek,\n",
    "            'num_of_hops': s1d1df_old.loc[i, 'NUM_HOPS']\n",
    "        }\n",
    "        new_rows.append(new_row)\n",
    "new_rows_df = pd.DataFrame(new_rows)\n",
    "new_rows_df['rolling_avg'] = new_rows_df['ping'].rolling(window=1000).mean()\n",
    "total_df = pd.concat([total_df, new_rows_df], ignore_index=True)\n",
    "total_df\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b64b5-f3fe-495c-ac03-aeab0712cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "for i in range(len(s1d2df)):\n",
    "    for ping_column in ['PING2', 'PING3', 'PING4','PING5', 'PING6', 'PING7', 'PING8', 'PING9', 'PING10']:\n",
    "        new_row = {\n",
    "            'ping': s1d2df.loc[i, ping_column],\n",
    "            'dest_cmu': 0,\n",
    "            'dest_aws': 1,\n",
    "            'TIMESTAMP': int(s1d2df.loc[i, 'TIMESTAMP'].timestamp()),\n",
    "            'min_of_day': (s1d2df.loc[i, 'TIMESTAMP'].hour*60 + s1d2df.loc[i, 'TIMESTAMP'].minute),\n",
    "            'min_of_day_norm': (s1d2df.loc[i, 'TIMESTAMP'].hour*60 + s1d2df.loc[i, 'TIMESTAMP'].minute)/(60*24)*(4*np.pi),\n",
    "            'hour_of_day': s1d2df.loc[i, 'TIMESTAMP'].hour,\n",
    "            'day_of_week': s1d2df.loc[i, 'TIMESTAMP'].dayofweek,\n",
    "            'num_of_hops': s1d2df.loc[i, 'NUM_HOPS']\n",
    "        }\n",
    "        new_rows.append(new_row)\n",
    "new_rows_df = pd.DataFrame(new_rows)\n",
    "new_rows_df['rolling_avg'] = new_rows_df['ping'].rolling(window=1000).mean()\n",
    "total_df = pd.concat([total_df, new_rows_df], ignore_index=True)\n",
    "total_df\n",
    "\n",
    "\"\"\"new_rows = []\n",
    "for i in range(len(s1d2df_old)):\n",
    "    for ping_column in ['PING2', 'PING3', 'PING4','PING5']:\n",
    "        new_row = {\n",
    "            'ping': s1d2df_old.loc[i, ping_column],\n",
    "            'dest_cmu': 1,\n",
    "            'dest_aws': 0,\n",
    "            'TIMESTAMP': int(s1d2df_old.loc[i, 'TIMESTAMP'].timestamp()),\n",
    "            'min_of_day': (s1d2df_old.loc[i, 'TIMESTAMP'].hour*60 + s1d2df_old.loc[i, 'TIMESTAMP'].minute),\n",
    "            'min_of_day_norm': (s1d2df_old.loc[i, 'TIMESTAMP'].hour*60 + s1d2df_old.loc[i, 'TIMESTAMP'].minute)/(60*24)*(4*np.pi),\n",
    "            'hour_of_day': s1d2df_old.loc[i, 'TIMESTAMP'].hour,\n",
    "            'day_of_week': s1d2df_old.loc[i, 'TIMESTAMP'].dayofweek,\n",
    "            'num_of_hops': s1d2df_old.loc[i, 'NUM_HOPS']\n",
    "        }\n",
    "        new_rows.append(new_row)\n",
    "new_rows_df = pd.DataFrame(new_rows)\n",
    "print(new_rows_df)\n",
    "new_rows_df['rolling_avg'] = new_rows_df['ping'].rolling(window=1000).mean()\n",
    "total_df = pd.concat([total_df, new_rows_df], ignore_index=True)\n",
    "total_df\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6fd25-680f-4c87-a1d8-ebacdb9bf923",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df.dropna(subset=['ping'])\n",
    "total_df = total_df.dropna(subset=['rolling_avg'])\n",
    "total_df = total_df.reset_index(drop=True)\n",
    "total_df['min_cos'] = np.cos(total_df['min_of_day_norm'])\n",
    "total_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c31ac9f-7120-41f2-827f-12feae1fbec5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# additional sin/cos tests with Jim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369d36c9-939c-4808-b9fa-60870020d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfx = total_df.copy()\n",
    "tdfx['min_cos'] = total_df['min_of_day_norm'].map(lambda xx: math.cos(xx))\n",
    "#tdfx=total_df.drop_duplicates([\"min_of_day_norm\"]).reset_index().reset_index()\n",
    "tdfx\n",
    "lineplot(total_df.iloc[0:10000], \"index\", ['min_cos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057674aa-8046-48ce-8889-218de3d33747",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=list(range(0,round(4*np.pi+1)))\n",
    "print(index)\n",
    "tdfx=pd.DataFrame(index, columns=[\"range\"])\n",
    "tdfx['range'] = tdfx.range\n",
    "tdfx[\"cos\"] = np.cos(tdfx.range)\n",
    "print(tdfx)\n",
    "lineplot(tdfx,'range', ['cos'])\n",
    "\n",
    "#np.cos(np.array([0, np.pi/2, np.pi]))\n",
    "tdfy = pd.DataFrame(np.cos(np.array([0, np.pi/2, np.pi])))\n",
    "#tdfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d177b478-9d40-4c59-b680-867c99ca621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tdfx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea6a10-537b-42a2-80b2-1db0b7cad527",
   "metadata": {},
   "source": [
    "# sklearn modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e173f-6ccc-4a42-8dbd-ea50295e5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent variables (X) and dependent variable (y)\n",
    "X = total_df[['dest_cmu', 'hour_of_day', 'day_of_week', 'num_of_hops']]\n",
    "y = total_df['rolling_avg']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create a DataFrame to display predicted and actual values\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted': y_pred,\n",
    "    'Actual': y_test.values\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"Predicted vs Actual values:\")\n",
    "print(results_df)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Get the coefficients of the model\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': coefficients\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "print(feature_importance)\n",
    "print(\"Intercept (constant term):\", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af6d20-2c6b-463c-9915-effa2c5b6fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have 'dest_cmu' in X_test\n",
    "dest_cmu_values = X_test['dest_cmu'].values\n",
    "\n",
    "# Add 'Destination' as a new column in the results DataFrame\n",
    "results_df['Destination'] = dest_cmu_values\n",
    "\n",
    "# Display the DataFrame to check the result\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14844e6-56b2-4d7a-89ab-0f74fe378116",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"y_pred\"] = model.predict(X)\n",
    "total_df\n",
    "tdfx=total_df[total_df.dest_cmu==1].iloc[0:100]\n",
    "lineplot(tdfx, 'index', ['rolling_avg', 'y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c04b8-022d-468c-8e22-fc3e09fb6e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot(results_df.iloc[0:100], 'index', ['Actual', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce5c67-83b8-46ab-9611-ce44676c122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatterplot\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(results_df['Actual'].iloc[0:100], results_df['Predicted'].iloc[0:100])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Scatterplot of Actual vs Predicted Values')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703b3f7-e410-4fc9-843c-58d4f570ce31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the results DataFrame based on the 'Destination' values\n",
    "teal_points = results_df[results_df['Destination'] == 1]\n",
    "orange_points = results_df[results_df['Destination'] == 0]\n",
    "\n",
    "# Create the scatterplot\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "# Plot teal points where 'Destination' is 1\n",
    "plt.scatter(teal_points['Actual'], teal_points['Predicted'], color='teal', label='Destination = 1')\n",
    "\n",
    "# Plot orange points where 'Destination' is 0\n",
    "plt.scatter(orange_points['Actual'], orange_points['Predicted'], color='orange', label='Destination = 0')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Scatterplot of Actual vs Predicted Values')\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edacdbcc-3d0a-4428-92c5-e712c590aa0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7dda94-1149-4dc9-8ebf-c35275de2949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    " \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(4, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99ebb0-b09a-4d30-a9cb-a5528fc28447",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = total_df.sample(frac=0.2, random_state=2) \n",
    "training_df = total_df.drop(test_df.index)\n",
    "test_df\n",
    "training_df\n",
    "\n",
    "# Ensure there are no NaN values and that all data types are numerical\n",
    "training_df[['dest_cmu', 'hour_of_day', 'day_of_week', 'num_of_hops']] = training_df[['dest_cmu', 'hour_of_day', 'day_of_week', 'num_of_hops']].apply(pd.to_numeric, errors='coerce')\n",
    "training_df = training_df.dropna()\n",
    "\n",
    "test_df[['dest_cmu', 'hour_of_day', 'day_of_week', 'num_of_hops']] = test_df[['dest_cmu', 'hour_of_day', 'day_of_week', 'num_of_hops']].apply(pd.to_numeric, errors='coerce')\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "# Convert features and labels to numpy arrays\n",
    "x_train = training_df[['dest_cmu', 'hour_of_day', 'day_of_week', 'num_of_hops']].values\n",
    "y_train = training_df['rolling_avg'].values\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "x_test = test_df[['dest_cmu', 'hour_of_day', 'day_of_week', 'num_of_hops']].values\n",
    "y_test = test_df['rolling_avg'].values\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe880f-6e3e-4dd7-a612-bccd756d0e17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    optimizer.zero_grad()  # Clear gradients from previous iteration\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train_tensor)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_fn(y_pred.squeeze(), y_train_tensor)  # Squeeze y_pred to match y_train_tensor shape\n",
    "    print(loss.item())\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "#print(model)\n",
    "print(y_pred)\n",
    "print(y_train_tensor)\n",
    "# Compute validation loss\n",
    "val_loss = loss_fn(y_pred.squeeze(), y_train_tensor)\n",
    "    \n",
    "# Print validation loss (optional)\n",
    "print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {val_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126243c-57ea-41e6-b1eb-148aa77d94cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Forward pass on validation data\n",
    "    y_pred_val = model(x_test_tensor)\n",
    "    \n",
    "    # Compute validation loss\n",
    "    val_loss = loss_fn(y_pred_val.squeeze(), y_test_tensor)\n",
    "    \n",
    "    # Print validation loss (optional)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "x_test = x_test_tensor.detach().numpy()\n",
    "y_test = y_test_tensor.detach().numpy()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    #'x_test_1': x_test_tensor[:, 0].flatten(),  # Assuming x_test has 2 columns, showing the first one\n",
    "    #'x_test_2': x_test_tensor[:, 1].flatten(),  # Assuming x_test has 2 columns, showing the second one\n",
    "    'y_test': y_test_tensor.flatten(),\n",
    "    'y_pred': y_pred_val.flatten(),\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd20c3c-9ed6-48c5-8881-ab96672d4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Forward pass on validation data\n",
    "    y_pred_val = model(x_test_tensor)\n",
    "    \n",
    "    # Compute validation loss\n",
    "    val_loss = loss_fn(y_pred_val.squeeze(), y_test_tensor)\n",
    "    \n",
    "    # Print validation loss (optional)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "x_test = x_test_tensor.detach().numpy()\n",
    "y_test = y_test_tensor.detach().numpy()\n",
    "y_pred = y_pred_val.squeeze().detach().numpy()  # Ensure the shape is correct\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'MSE: {mse:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "\n",
    "# Create a DataFrame for visualization or analysis\n",
    "df = pd.DataFrame({\n",
    "    #'x_test_1': x_test_tensor[:, 0].flatten(),  # Assuming x_test has 2 columns, showing the first one\n",
    "    #'x_test_2': x_test_tensor[:, 1].flatten(),  # Assuming x_test has 2 columns, showing the second one\n",
    "    'y_test': y_test.flatten(),\n",
    "    'y_pred': y_pred.flatten(),\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27abb03d-8cbf-45e9-a7d0-65a78b6977dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Destination'] = test_df['dest_cmu'].values\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e32fc8-42fa-4dd9-9a2b-f33d46694538",
   "metadata": {},
   "outputs": [],
   "source": [
    "lineplot(df.iloc[0:100], 'index', ['y_test', 'y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a5e1e-4428-4da0-a761-3a041b106798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the scatterplot\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(df['y_test'].iloc[0:100], df['y_pred'].iloc[0:100])\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Scatterplot of Actual vs Predicted Values')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec307dae-1935-4dca-901d-fb25c17ab15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = df['Destination'].apply(lambda x: 'teal' if x == 1 else 'orange')\n",
    "\n",
    "# Create the scatterplot\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.scatter(df['y_test'], df['y_pred'], c=colors)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Scatterplot of Actual vs Predicted Values')\n",
    "\n",
    "# Add a legend\n",
    "import matplotlib.patches as mpatches\n",
    "blue_patch = mpatches.Patch(color='teal', label='CMU')\n",
    "red_patch = mpatches.Patch(color='orange', label='AWS')\n",
    "plt.legend(handles=[blue_patch, red_patch])\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
