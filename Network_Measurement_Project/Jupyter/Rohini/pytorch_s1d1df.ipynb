{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f2bb2d-c895-44d8-b3e1-efc5d98f2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    " \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 1)\n",
    ")\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a73e399-6554-498d-a514-6b0df3cd58ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>ping</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_week_number</th>\n",
       "      <th>normalized_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-22 12:55:17.235189</td>\n",
       "      <td>58.00000000</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>12</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0.60000000</td>\n",
       "      <td>0.53839120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-22 12:55:17.235189</td>\n",
       "      <td>56.00000000</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>12</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0.60000000</td>\n",
       "      <td>0.53839120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-22 12:55:17.235189</td>\n",
       "      <td>54.00000000</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>12</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0.60000000</td>\n",
       "      <td>0.53839120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-22 12:55:17.235189</td>\n",
       "      <td>53.00000000</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>12</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0.60000000</td>\n",
       "      <td>0.53839120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-22 12:55:17.235189</td>\n",
       "      <td>53.00000000</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>12</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0.60000000</td>\n",
       "      <td>0.53839120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6406</th>\n",
       "      <td>2024-04-09 06:42:12.659485</td>\n",
       "      <td>44.00000000</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>6</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0.30000000</td>\n",
       "      <td>0.27930556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>2024-04-09 07:16:19.492482</td>\n",
       "      <td>8.00000000</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>7</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0.30000000</td>\n",
       "      <td>0.30299769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6408</th>\n",
       "      <td>2024-04-09 07:16:19.492482</td>\n",
       "      <td>51.00000000</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>7</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0.30000000</td>\n",
       "      <td>0.30299769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>2024-04-09 08:07:29.063338</td>\n",
       "      <td>6.00000000</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>8</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0.30000000</td>\n",
       "      <td>0.33853009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6410</th>\n",
       "      <td>2024-04-09 08:07:29.063338</td>\n",
       "      <td>62.00000000</td>\n",
       "      <td>2024-04-09</td>\n",
       "      <td>8</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0.30000000</td>\n",
       "      <td>0.33853009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6411 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      TIMESTAMP        ping       date  hour day_of_week  \\\n",
       "0    2024-03-22 12:55:17.235189 58.00000000 2024-03-22    12      Friday   \n",
       "1    2024-03-22 12:55:17.235189 56.00000000 2024-03-22    12      Friday   \n",
       "2    2024-03-22 12:55:17.235189 54.00000000 2024-03-22    12      Friday   \n",
       "3    2024-03-22 12:55:17.235189 53.00000000 2024-03-22    12      Friday   \n",
       "4    2024-03-22 12:55:17.235189 53.00000000 2024-03-22    12      Friday   \n",
       "...                         ...         ...        ...   ...         ...   \n",
       "6406 2024-04-09 06:42:12.659485 44.00000000 2024-04-09     6     Tuesday   \n",
       "6407 2024-04-09 07:16:19.492482  8.00000000 2024-04-09     7     Tuesday   \n",
       "6408 2024-04-09 07:16:19.492482 51.00000000 2024-04-09     7     Tuesday   \n",
       "6409 2024-04-09 08:07:29.063338  6.00000000 2024-04-09     8     Tuesday   \n",
       "6410 2024-04-09 08:07:29.063338 62.00000000 2024-04-09     8     Tuesday   \n",
       "\n",
       "      day_of_week_number  normalized_time  \n",
       "0             0.60000000       0.53839120  \n",
       "1             0.60000000       0.53839120  \n",
       "2             0.60000000       0.53839120  \n",
       "3             0.60000000       0.53839120  \n",
       "4             0.60000000       0.53839120  \n",
       "...                  ...              ...  \n",
       "6406          0.30000000       0.27930556  \n",
       "6407          0.30000000       0.30299769  \n",
       "6408          0.30000000       0.30299769  \n",
       "6409          0.30000000       0.33853009  \n",
       "6410          0.30000000       0.33853009  \n",
       "\n",
       "[6411 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "s1d1df = pd.read_csv('s1d1pings.csv')\n",
    "s1d1df['TIMESTAMP'] = pd.to_datetime(s1d1df['TIMESTAMP'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "s1d1df.reset_index\n",
    "\n",
    "s1d1df['date'] = pd.to_datetime(s1d1df['date'], format='%Y-%m-%d')\n",
    "s1d1df['day_of_week'] = s1d1df['date'].dt.day_name()\n",
    "s1d1df['day_of_week'] = s1d1df['date'].dt.day_name()\n",
    "day_to_number = {\n",
    "    'Sunday': 0.1,\n",
    "    'Monday': 0.2,\n",
    "    'Tuesday': 0.3,\n",
    "    'Wednesday': 0.4,\n",
    "    'Thursday': 0.5,\n",
    "    'Friday': 0.6,\n",
    "    'Saturday': 0.7\n",
    "}\n",
    "s1d1df['day_of_week_number'] = s1d1df['day_of_week'].map(day_to_number)\n",
    "\n",
    "s1d1df['normalized_time'] = (s1d1df['TIMESTAMP'].dt.hour * 3600 + s1d1df['TIMESTAMP'].dt.minute * 60 + s1d1df['TIMESTAMP'].dt.second) / 86400\n",
    "pd.set_option('display.float_format', '{:.8f}'.format)\n",
    "s1d1df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0f5c559-d761-4f22-a120-c469e70c14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = s1d1df.sample(frac=0.2, random_state=2) \n",
    "training_df = s1d1df.drop(test_df.index)\n",
    "test_df\n",
    "training_df\n",
    "\n",
    "x_train = training_df[['normalized_time', 'day_of_week_number']].values  # Features\n",
    "y_train = training_df['ping'].values/100  # Labels\n",
    "# Convert to PyTorch tensors\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "x_test = test_df[['normalized_time', 'day_of_week_number']].values  # Features\n",
    "y_test = test_df['ping'].values/100  # Labels\n",
    "# Convert to PyTorch tensors\n",
    "x_test_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_train, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea836acb-cf9d-47f3-9d9c-09a9d53b27a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3124854266643524\n",
      "0.3054186999797821\n",
      "0.298404723405838\n",
      "0.291433185338974\n",
      "0.28450456261634827\n",
      "0.2776572108268738\n",
      "0.2708943784236908\n",
      "0.26421841979026794\n",
      "0.2576313614845276\n",
      "0.2511352002620697\n",
      "0.24473172426223755\n",
      "0.23842264711856842\n",
      "0.23220953345298767\n",
      "0.22609378397464752\n",
      "0.2200765609741211\n",
      "0.21415923535823822\n",
      "0.20834289491176605\n",
      "0.20262877643108368\n",
      "0.19701765477657318\n",
      "0.19151082634925842\n",
      "0.18610879778862\n",
      "0.1808125525712967\n",
      "0.17562271654605865\n",
      "0.17053991556167603\n",
      "0.165564626455307\n",
      "0.16069746017456055\n",
      "0.15593869984149933\n",
      "0.15128874778747559\n",
      "0.14674785733222961\n",
      "0.14231613278388977\n",
      "0.13799376785755157\n",
      "0.13378076255321503\n",
      "0.12967704236507416\n",
      "0.12568256258964539\n",
      "0.12179713696241379\n",
      "0.11802033334970474\n",
      "0.11435201019048691\n",
      "0.1107916459441185\n",
      "0.10733877867460251\n",
      "0.10399282723665237\n",
      "0.10075312107801437\n",
      "0.09761886298656464\n",
      "0.09458926320075989\n",
      "0.0916634202003479\n",
      "0.08884046226739883\n",
      "0.08611937612295151\n",
      "0.08349922299385071\n",
      "0.08097866177558899\n",
      "0.0785563737154007\n",
      "0.07623110711574554\n",
      "0.0740015059709549\n",
      "0.07186595350503922\n",
      "0.06982286274433136\n",
      "0.06787064671516418\n",
      "0.06600750982761383\n",
      "0.06423159688711166\n",
      "0.0625411868095398\n",
      "0.06093425676226616\n",
      "0.059408608824014664\n",
      "0.05796237289905548\n",
      "0.05659346655011177\n",
      "0.05529964342713356\n",
      "0.054078660905361176\n",
      "0.052928272634744644\n",
      "0.05184611678123474\n",
      "0.05082979425787926\n",
      "0.04987689107656479\n",
      "0.048984963446855545\n",
      "0.048151493072509766\n",
      "0.04737399145960808\n",
      "0.04665010794997215\n",
      "0.04597707837820053\n",
      "0.045352619141340256\n",
      "0.04477430135011673\n",
      "0.04423950985074043\n",
      "0.043745871633291245\n",
      "0.043290875852108\n",
      "0.04287212714552879\n",
      "0.042487580329179764\n",
      "0.04213481768965721\n",
      "0.0418117418885231\n",
      "0.0415165014564991\n",
      "0.04124687612056732\n",
      "0.04100095108151436\n",
      "0.04077676311135292\n",
      "0.040572404861450195\n",
      "0.04038610681891441\n",
      "0.04021627828478813\n",
      "0.040061384439468384\n",
      "0.03991992026567459\n",
      "0.03979057818651199\n",
      "0.03967227786779404\n",
      "0.03956373780965805\n",
      "0.0394638292491436\n",
      "0.0393715463578701\n",
      "0.03928590193390846\n",
      "0.03920574486255646\n",
      "0.03913012519478798\n",
      "0.03905860707163811\n",
      "0.03899059444665909\n",
      "0.03892570361495018\n",
      "0.038863107562065125\n",
      "0.038802370429039\n",
      "0.03874307870864868\n",
      "0.038684796541929245\n",
      "0.038627225905656815\n",
      "0.03857029229402542\n",
      "0.03851304203271866\n",
      "0.038455426692962646\n",
      "0.03839794918894768\n",
      "0.0383402481675148\n",
      "0.03828197345137596\n",
      "0.03822307288646698\n",
      "0.0381636805832386\n",
      "0.038103800266981125\n",
      "0.03804311901330948\n",
      "0.03798168897628784\n",
      "0.03792022913694382\n",
      "0.03785824030637741\n",
      "0.03779502213001251\n",
      "0.03773142397403717\n",
      "0.03766745701432228\n",
      "0.03760378435254097\n",
      "0.03754017874598503\n",
      "0.0374772809445858\n",
      "0.037415146827697754\n",
      "0.037353646010160446\n",
      "0.03729246184229851\n",
      "0.0372319221496582\n",
      "0.0371723510324955\n",
      "0.037114035338163376\n",
      "0.0370565764605999\n",
      "0.03700023144483566\n",
      "0.03694519028067589\n",
      "0.036890920251607895\n",
      "0.03683764487504959\n",
      "0.036785777658224106\n",
      "0.036735158413648605\n",
      "0.03668542206287384\n",
      "0.03663639351725578\n",
      "0.036588188260793686\n",
      "0.03654104098677635\n",
      "0.03649483621120453\n",
      "0.03644955903291702\n",
      "0.036404818296432495\n",
      "0.03636089339852333\n",
      "0.03631802275776863\n",
      "0.03627593815326691\n",
      "0.036234740167856216\n",
      "0.03619410842657089\n",
      "0.036154042929410934\n",
      "0.03611457720398903\n",
      "0.03607576712965965\n",
      "0.036037541925907135\n",
      "0.03599982336163521\n",
      "0.03596251457929611\n",
      "0.03592563793063164\n",
      "0.03588912636041641\n",
      "0.035852957516908646\n",
      "0.03581719100475311\n",
      "0.03578183799982071\n",
      "0.03574683144688606\n",
      "0.03571217507123947\n",
      "0.03567788749933243\n",
      "0.03564393147826195\n",
      "0.035610295832157135\n",
      "0.03557700291275978\n",
      "0.035544056445360184\n",
      "0.03551142290234566\n",
      "0.0354791060090065\n",
      "0.03544706851243973\n",
      "0.03541531413793564\n",
      "0.03538382425904274\n",
      "0.035352595150470734\n",
      "0.035321593284606934\n",
      "0.035290833562612534\n",
      "0.03526027873158455\n",
      "0.03522992134094238\n",
      "0.03519977256655693\n",
      "0.035169828683137894\n",
      "0.03514006733894348\n",
      "0.035110488533973694\n",
      "0.03508109226822853\n",
      "0.0350518673658371\n",
      "0.03502282872796059\n",
      "0.03499395027756691\n",
      "0.03496525436639786\n",
      "0.03493671864271164\n",
      "0.03490834683179855\n",
      "0.0348801463842392\n",
      "0.03485211357474327\n",
      "0.03482425585389137\n",
      "0.03479655832052231\n",
      "0.03476900979876518\n",
      "0.034741610288619995\n",
      "0.03471436724066734\n",
      "0.03468726575374603\n",
      "0.03466031327843666\n",
      "0.034633517265319824\n",
      "0.034606873989105225\n",
      "0.03458039090037346\n",
      "0.03455406799912453\n",
      "0.034527890384197235\n",
      "0.03450186550617218\n",
      "0.034475989639759064\n",
      "0.03445028141140938\n",
      "0.03442472964525223\n",
      "0.03439932316541672\n",
      "0.03437407314777374\n",
      "0.03434896469116211\n",
      "0.034324005246162415\n",
      "0.03429918736219406\n",
      "0.034274499863386154\n",
      "0.03424995765089989\n",
      "0.03422555327415466\n",
      "0.03420128673315048\n",
      "0.034177158027887344\n",
      "0.034153178334236145\n",
      "0.034129321575164795\n",
      "0.03410560265183449\n",
      "0.034082021564245224\n",
      "0.034058570861816406\n",
      "0.03403525426983833\n",
      "0.034012068063020706\n",
      "0.033989015966653824\n",
      "0.03396609425544739\n",
      "0.03394331410527229\n",
      "0.03392064943909645\n",
      "0.033898111432790756\n",
      "0.033875707536935806\n",
      "0.033853426575660706\n",
      "0.03383126109838486\n",
      "0.03380922973155975\n",
      "0.0337873212993145\n",
      "0.033765532076358795\n",
      "0.03374386578798294\n",
      "0.03372232988476753\n",
      "0.033700909465551376\n",
      "0.03367961198091507\n",
      "0.03365844115614891\n",
      "0.0336373932659626\n",
      "0.03361646085977554\n",
      "0.033595651388168335\n",
      "0.033574964851140976\n",
      "0.03355439379811287\n",
      "0.03353394195437431\n",
      "0.03351360186934471\n",
      "0.03349338471889496\n",
      "0.03347328305244446\n",
      "0.03345329314470291\n",
      "0.03343341872096062\n",
      "0.03341367095708847\n",
      "0.033394038677215576\n",
      "0.033374518156051636\n",
      "0.033355116844177246\n",
      "0.03333583101630211\n",
      "0.03331666439771652\n",
      "0.03329760581254959\n",
      "0.033278658986091614\n",
      "0.033259835094213486\n",
      "0.03324110805988312\n",
      "0.033222511410713196\n",
      "0.03320401534438133\n",
      "0.03318563476204872\n",
      "0.03316736966371536\n",
      "0.03314921632409096\n",
      "0.033131178468465805\n",
      "0.03311324492096901\n",
      "0.03309541940689087\n",
      "0.03307771682739258\n",
      "0.033060118556022644\n",
      "0.033042632043361664\n",
      "0.033025261014699936\n",
      "0.033007990568876266\n",
      "0.03299083933234215\n",
      "0.03297378867864609\n",
      "0.03295685350894928\n",
      "0.03294002637267113\n",
      "0.03292330726981163\n",
      "0.032906703650951385\n",
      "0.0328902006149292\n",
      "0.032873813062906265\n",
      "0.03285752981901169\n",
      "0.03284135460853577\n",
      "0.0328252799808979\n",
      "0.032809317111968994\n",
      "0.03279345855116844\n",
      "0.032777708023786545\n",
      "0.032762061804533005\n",
      "0.03274652361869812\n",
      "0.032731086015701294\n",
      "0.03271576762199402\n",
      "0.0327005535364151\n",
      "0.03268544003367424\n",
      "0.03267043083906174\n",
      "0.03265552222728729\n",
      "0.032640717923641205\n",
      "0.032626014202833176\n",
      "0.0326114185154438\n",
      "0.03259691596031189\n",
      "tensor([[0.5113],\n",
      "        [0.5113],\n",
      "        [0.5113],\n",
      "        ...,\n",
      "        [0.4357],\n",
      "        [0.4387],\n",
      "        [0.4387]], grad_fn=<AddmmBackward0>)\n",
      "tensor([0.5800, 0.5600, 0.5400,  ..., 0.4400, 0.0800, 0.5100])\n",
      "Epoch [300/300], Training Loss: 0.0326\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    optimizer.zero_grad()  # Clear gradients from previous iteration\n",
    "\n",
    "    # Forward pass\n",
    "    y_pred = model(x_train_tensor)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = loss_fn(y_pred.squeeze(), y_train_tensor)  # Squeeze y_pred to match y_train_tensor shape\n",
    "    print(loss.item())\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "#print(model)\n",
    "print(y_pred)\n",
    "print(y_train_tensor)\n",
    "# Compute validation loss\n",
    "val_loss = loss_fn(y_pred.squeeze(), y_train_tensor)\n",
    "    \n",
    "# Print validation loss (optional)\n",
    "print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {val_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "886f15f0-157d-4841-9961-f93d7d7729f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [300/300], Validation Loss: 0.0326\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_test_1</th>\n",
       "      <th>x_test_2</th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.53839123</td>\n",
       "      <td>0.60000002</td>\n",
       "      <td>0.57999998</td>\n",
       "      <td>0.51116395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.53839123</td>\n",
       "      <td>0.60000002</td>\n",
       "      <td>0.56000000</td>\n",
       "      <td>0.51116395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.53839123</td>\n",
       "      <td>0.60000002</td>\n",
       "      <td>0.54000002</td>\n",
       "      <td>0.51116395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.53839123</td>\n",
       "      <td>0.60000002</td>\n",
       "      <td>0.52999997</td>\n",
       "      <td>0.51116395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.53975695</td>\n",
       "      <td>0.60000002</td>\n",
       "      <td>0.57999998</td>\n",
       "      <td>0.51133823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5124</th>\n",
       "      <td>0.25528935</td>\n",
       "      <td>0.30000001</td>\n",
       "      <td>0.73000002</td>\n",
       "      <td>0.43282348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5125</th>\n",
       "      <td>0.27930555</td>\n",
       "      <td>0.30000001</td>\n",
       "      <td>0.10000000</td>\n",
       "      <td>0.43588755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5126</th>\n",
       "      <td>0.27930555</td>\n",
       "      <td>0.30000001</td>\n",
       "      <td>0.44000000</td>\n",
       "      <td>0.43588755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>0.30299768</td>\n",
       "      <td>0.30000001</td>\n",
       "      <td>0.08000000</td>\n",
       "      <td>0.43891025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5128</th>\n",
       "      <td>0.30299768</td>\n",
       "      <td>0.30000001</td>\n",
       "      <td>0.50999999</td>\n",
       "      <td>0.43891025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5129 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x_test_1   x_test_2     y_test     y_pred\n",
       "0    0.53839123 0.60000002 0.57999998 0.51116395\n",
       "1    0.53839123 0.60000002 0.56000000 0.51116395\n",
       "2    0.53839123 0.60000002 0.54000002 0.51116395\n",
       "3    0.53839123 0.60000002 0.52999997 0.51116395\n",
       "4    0.53975695 0.60000002 0.57999998 0.51133823\n",
       "...         ...        ...        ...        ...\n",
       "5124 0.25528935 0.30000001 0.73000002 0.43282348\n",
       "5125 0.27930555 0.30000001 0.10000000 0.43588755\n",
       "5126 0.27930555 0.30000001 0.44000000 0.43588755\n",
       "5127 0.30299768 0.30000001 0.08000000 0.43891025\n",
       "5128 0.30299768 0.30000001 0.50999999 0.43891025\n",
       "\n",
       "[5129 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    # Forward pass on validation data\n",
    "    y_pred_val = model(x_test_tensor)\n",
    "    \n",
    "    # Compute validation loss\n",
    "    val_loss = loss_fn(y_pred_val.squeeze(), y_test_tensor)\n",
    "    \n",
    "    # Print validation loss (optional)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss.item():.4f}')\n",
    "\n",
    "x_test = x_test_tensor.detach().numpy()\n",
    "y_test = y_test_tensor.detach().numpy()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'x_test_1': x_test_tensor[:, 0].flatten(),  # Assuming x_test has 2 columns, showing the first one\n",
    "    'x_test_2': x_test_tensor[:, 1].flatten(),  # Assuming x_test has 2 columns, showing the second one\n",
    "    'y_test': y_test_tensor.flatten(),\n",
    "    'y_pred': y_pred_val.flatten()\n",
    "\n",
    "})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
