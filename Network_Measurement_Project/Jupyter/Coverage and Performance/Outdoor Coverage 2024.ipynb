{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dfd35a-3535-4754-b1f7-211b988f5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# print(sys.path)\n",
    "import subprocess\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "import traceback\n",
    "import json\n",
    "from pyutils import *\n",
    "from pdutils import *\n",
    "from pdpltutils import *\n",
    "from gputils import *\n",
    "from iputils import *\n",
    "import xmltodict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a6fe9-53fa-4029-9e8e-0c691901af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == \"linux\":\n",
    "    DATADIR=\"/home/jblake1/Downloads/Network_Measurements\"\n",
    "else:\n",
    "    DATADIR=\"P:\\\\My Drive\\\\CMU-LEL\\\\Mill19\\\\Images\\\\Coverage and Performance\"\n",
    "    EXPDIR=os.path.join(*[DATADIR,\"2024-09-10-Mill19-Testing\",\"LEL-UE1\"])\n",
    "\n",
    "DIRCHECKLIST=[DATADIR,EXPDIR]\n",
    "for DIR in DIRCHECKLIST:\n",
    "    print(f\"{DIR} exists\") if os.path.isdir(DIR) else print(f\"{DIR} does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2abee6-4c61-415e-bd18-312d857ec8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pngfiles = [os.path.join(EXPDIR,fn) for fn in os.listdir(EXPDIR) if fn.endswith(\".png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252e680-95fb-4da5-bc5b-6f9f93146664",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfx = pd.DataFrame(pngfiles,columns=[\"PNGFFN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19206b-3f58-48f2-afce-d9c5628792f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfx['TXTFFN'] = tdfx.PNGFFN.str.replace(\".png\",\".txt\")\n",
    "tdfx['TXTEXISTS'] = tdfx.TXTFFN.map(lambda xx: os.path.exists(xx))\n",
    "tdfx['CSVFFN'] = tdfx.PNGFFN.str.replace(\".png\",\".csv\")\n",
    "tdfx['CSVEXISTS'] = tdfx.CSVFFN.map(lambda xx: os.path.exists(xx))\n",
    "tdfx['PNGDATE'] = tdfx.PNGFFN.map(lambda xx: os.path.basename(xx).replace(\"Screenshot_\",\"\").replace(\".png\",\"\"))\n",
    "tdfx = tdfx.sort_values([\"PNGFFN\"]).reset_index(drop=True)\n",
    "dumpdf(tdfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01764dcb-6a56-4d96-b7e8-2c944d55e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tdfx.TXTFFN.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5af093-0d74-46ac-af11-4b969837085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyFile(row):\n",
    "    fn = row['TXTFFN']\n",
    "    # print(fn)\n",
    "    lines = []\n",
    "    datalst = []\n",
    "    fclass = \"UNKNOWN\"\n",
    "    with open(fn,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.rstrip('\\n') for line in lines if line != \"\\n\" and line != \" \"]\n",
    "    pingfile, kwline = kwInFile(lines,\"PING\")\n",
    "    if pingfile:\n",
    "        fclass = \"PING\"\n",
    "        pdest = kwline.split(\" \")[0]\n",
    "        haspstats, pstats = kwInFile(lines,\"Ping statistics:\",offset=1)\n",
    "        haststats, tstats = kwInFile(lines,\"Time statistics:\",offset=1)\n",
    "        # print(f\"pdest={pdest},hasstats={haspstats}, pstats={pstats}, tstats={tstats},kwline={kwline}\\n\\n{lines}\")\n",
    "        datalst = [pdest,haspstats, pstats, haststats, tstats]\n",
    "    iperfile, kwline = kwInFile(lines,\"bit/sec\")\n",
    "    if iperfile:\n",
    "        fclass = \"IPERF\"\n",
    "        hasidest, kwline = kwInFile(lines,\" START\")\n",
    "        idest = kwline.split(\" \")[0]\n",
    "        hasircv, ircv = kwInFile(lines,\"Receiver summary\",offset=1)\n",
    "        hasisnd, isnd = kwInFile(lines,\"Sender summary\",offset=1)\n",
    "        # print(f\"idest={idest},hasircv={hasircv}, ircv={ircv}, isnd={isnd}\")\n",
    "        datalst = [idest,hasircv,ircv,hasisnd,isnd]\n",
    "        # print(datalst)\n",
    "    cellfile, kwline = kwInFile(lines,\"Longitude:\")\n",
    "    if cellfile:\n",
    "        fclass = \"CELL\"\n",
    "        geoloc = kwline\n",
    "        hascperf, cperf = kwInFile(lines,\"SNR:\")\n",
    "        datalst = [geoloc, hascperf, cperf]\n",
    "\n",
    "    mapfile, kwline = kwInFile(lines,\"314-737\")\n",
    "    if mapfile:\n",
    "        fclass = \"MAP\"\n",
    "        hasmperf, mperf = kwInFile(lines,\"SNR:\")\n",
    "        hasminfo, minfo = kwInFile(lines,\"PCI:\")\n",
    "        datalst = [hasmperf, mperf, hasminfo,minfo]\n",
    "\n",
    "    speedfile, kwline = kwInFile(lines,\"Internet speed test\")\n",
    "    if speedfile:\n",
    "        fclass = \"SPEED\"\n",
    "        hasspeed, speed = kwInFile(lines,\"Internet speed test\",offset=1)\n",
    "        datalst = [hasspeed, speed]\n",
    "    \n",
    "    return fclass,datalst\n",
    "\n",
    "def kwInFile(lines,kw,offset=0):\n",
    "    retval = False\n",
    "    for ii,line in enumerate(lines):\n",
    "        if kw in line:\n",
    "            retval = True\n",
    "            break\n",
    "    return retval,lines[ii+offset]\n",
    "    \n",
    "\n",
    "tdfx[['FCLASS','DATALST']] = tdfx.apply(classifyFile,axis=1,result_type=\"expand\")\n",
    "dumpdf(tdfx,head = 20)\n",
    "# tdfx[:6].apply(classifyFile,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb6e71e-422b-4e39-afdb-55e3c51ac5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfx['DATAFIELD1'] = tdfx.DATALST.map(len).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37c378-6bae-4200-9ae8-0a32c02f3814",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfx[['DATAFIELD1','DATAFIELD2','DATAFIELD3','DATAFIELD4','DATAFIELD5']] = pd.DataFrame(tdfx.DATALST.tolist(),index = tdfx.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da6d06-31ce-42fc-93e0-c347775ed102",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumpdf(tdfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa191a7-7ed9-4512-bfb8-ab24cf2a342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfx = drp_lst(tdfx,[\"DATALST\"])\n",
    "dumpdf(tdfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab371aa8-a9ef-4e1a-9cca-7caad142239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "writejoin(tdfx,\".\",\"tmp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc185fcb-c5f9-4578-b33d-6a90b136dd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tdfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d29ebbd-50d1-4153-8971-86047f4851a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfy = drp_lst(readjoin(\".\",\"tmp-edited.csv\"),['Unnamed: 0'])\n",
    "dumpdf(tdfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b390aad-23cf-43aa-9d92-78d2ed1a8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ping Stats\n",
    "bdf = (tdfy.FCLASS == \"PING\") & (tdfy.DATAFIELD2)\n",
    "tdfy['PINGSTATS'] = tdfy[bdf].DATAFIELD3.map(lambda xx: [xx.split(\" \")[0], float(xx.split(\" \")[4].strip(\"%\"))])\n",
    "dumpdf(tdfy[bdf].PINGSTATS,head=len(tdfy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932ae53d-cbfc-4406-a77b-e2334a4a54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ping Times\n",
    "bdf = (tdfy.FCLASS == \"PING\") & (tdfy.DATAFIELD4)\n",
    "tdfy['PINGTIMES'] = tdfy[bdf].DATAFIELD5.map(lambda xx: re.sub(\"\\s\\s+\" , \" \", xx.replace(\"\\\\\",\"\")).split(\" \")[1::2])\n",
    "dumpdf(tdfy[bdf].PINGTIMES,head=len(tdfy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd2e8d-a4e5-4d69-b3e9-c51a99f9227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iperf\n",
    "def parseIperf(txt):\n",
    "    try:\n",
    "        retval = float(re.search(r'\\S+$',txt).group(0).rstrip(\"M\"))\n",
    "    except:\n",
    "        retval = np.nan\n",
    "    return retval\n",
    "bdf = (tdfy.FCLASS == \"IPERF\") & (tdfy.DATAFIELD4) & (tdfy.DATAFIELD2)\n",
    "tdfy['IPERFRCV'] = tdfy[bdf][0:].DATAFIELD3.map(parseIperf)\n",
    "tdfy['IPERFSND'] = tdfy[bdf][0:].DATAFIELD5.map(parseIperf)\n",
    "dumpdf(tdfy[bdf][['DATAFIELD3','IPERFRCV','DATAFIELD5','IPERFSND']],head=len(tdfy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21669a59-a264-4d6a-8b44-3533a102280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell\n",
    "bdf = (tdfy.FCLASS == \"CELL\") & (tdfy.DATAFIELD1.str.len() > 0)\n",
    "tdfy['GEOLOC'] = tdfy[bdf].DATAFIELD1.map(lambda xx: re.sub(\"\\s\\s+\" , \" \", xx.replace(\":\",\"\")).split(\" \")[1::2])\n",
    "tdfy['GEOLOC'] = tdfy[bdf].GEOLOC.map(lambda xx: [float(yy) for yy in xx])\n",
    "type(tdfy[bdf].GEOLOC.iloc[0][0])\n",
    "\n",
    "def parseCell(txt):\n",
    "    retval = []\n",
    "    if txt == '':\n",
    "        return retval\n",
    "    ntxt = re.sub(\"/\",\"\",txt)\n",
    "    try:\n",
    "        retval = [float(xx) for xx in re.search(\"^RSRP.*: [-+]?[0-9]+ RSRQ: [-+]?[0-9]+ SNR: [-+]?[0-9]+\",ntxt).group(0).split(\" \")[1::2]]\n",
    "        print(f\"'{retval}'\")\n",
    "    except:\n",
    "        retval = []\n",
    "    return retval\n",
    "bdf = (tdfy.FCLASS == \"CELL\") & (tdfy.DATAFIELD2)\n",
    "tdfy['MAPSIGNAL'] = tdfy[bdf].DATAFIELD3.map(parseCell)\n",
    "# dumpdf(tdfy[bdf].DATAFIELD3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e276ea24-f9d3-42c3-b6eb-5e050adf400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map\n",
    "def parseCellSignal(txt):\n",
    "    # print(txt)\n",
    "    retval = []\n",
    "    if txt == '':\n",
    "        return retval\n",
    "    ntxt = re.sub(\"/\",\"\",txt)\n",
    "    try:\n",
    "        retval = [float(xx) for xx in re.search(\"^RSRP.*: [-+]?[0-9]+ RSRQ: [-+]?[0-9]+ SNR: [-+]?[0-9]+\",ntxt).group(0).split(\" \")[1::2]]\n",
    "        # print(f\"'{retval}'\")\n",
    "    except:\n",
    "        try:\n",
    "            retval = [float(xx) for xx in re.search(\"RSRQ: [-+]?[0-9]+ SNR: [-+]?[0-9]+\",ntxt).group(0).split(\" \")[1::2]]\n",
    "            retval.insert(0,np.nan)\n",
    "            # print(f\"'{retval}'\")\n",
    "        except:\n",
    "            retval = []\n",
    "    return retval\n",
    "bdf = (tdfy.FCLASS == \"MAP\")  & (tdfy.DATAFIELD1)\n",
    "tdfy['CELLSIGNAL'] = tdfy[bdf].DATAFIELD2.map(parseCellSignal)\n",
    "\n",
    "def parseCellInfo(txt):\n",
    "    retval = []\n",
    "    try:\n",
    "        retval = re.search(\"gNB [0-9]+ Cl [0-9]+ PCI [0-9]+\",re.sub(\":\",\" \",txt)).group(0).split(\" \")[1::2]\n",
    "    except:\n",
    "        retval = []\n",
    "    return retval\n",
    "\n",
    "bdf = (tdfy.FCLASS == \"MAP\")  & (tdfy.DATAFIELD3)\n",
    "tdfy['CELLINFO'] = tdfy[bdf].DATAFIELD4.map(parseCellInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85796e4b-476e-4a7f-8f98-9c7642505b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed Test\n",
    "bdf = (tdfy.FCLASS == \"SPEED\")  & (tdfy.DATAFIELD1)\n",
    "dumpdf(tdfy[bdf].DATAFIELD2,head=20)\n",
    "tdfy['SPEEDINFO'] = tdfy[bdf].DATAFIELD2.map(lambda xx: [float(yy) for yy in xx.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9fff4-42d0-4108-8eb9-a12629459777",
   "metadata": {},
   "outputs": [],
   "source": [
    "writejoin(tdfy.set_index('PNGFFN'),EXPDIR,\"tmp-parsed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b3890f-6672-48a4-a12f-cc2be2bd9e2d",
   "metadata": {},
   "source": [
    "### Expand Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c199c94-8dc0-49b2-8e3b-74dc76b7ac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfy = readjoin(EXPDIR,\"tmp-parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398fbe23-c730-449e-8210-91f373ab699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tdfy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9af712-6aac-440c-adb0-c378c9df5db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keepcol=['GROUP', 'PNGDATE','TEST_UE', 'SCELLID', 'PINGSTATS', 'PINGTIMES',\n",
    "       'IPERFRCV', 'IPERFSND', 'GEOLOC', 'MAPSIGNAL', 'CELLSIGNAL', 'CELLINFO',\n",
    "       'SPEEDINFO']\n",
    "tdfy = tdfy[keepcol]\n",
    "dumpdf(tdfy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deb1157-07d0-47e0-8ea4-34876d89f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgbx = tdfy.groupby('GROUP')\n",
    "\n",
    "def collapseGroup(fdf):\n",
    "    rdf = fdf.ffill().iloc[-1].to_frame().T\n",
    "    return rdf\n",
    "\n",
    "tdfz = pd.DataFrame()\n",
    "for key, groupdf in tgbx:\n",
    "    tdfz = pd.concat([tdfz,collapseGroup(groupdf)])\n",
    "\n",
    "dumpdf(tdfz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74439d0-2a9c-4f5d-a333-720f7617670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2Float(sinlst,lstsize=2):\n",
    "    outlst = []\n",
    "    inlst = []\n",
    "    if isinstance(sinlst,str):\n",
    "        inlst = [item.strip(\" '\") for item in sinlst.strip(\"[]\").split(\",\")]\n",
    "        # print(inlst)\n",
    "        for item in inlst:\n",
    "            try:\n",
    "                outval = float(item)\n",
    "            except:\n",
    "                outval = np.nan\n",
    "            outlst.append(outval)\n",
    "    else:\n",
    "        outlst = [np.nan for ii in range(0,lstsize)]\n",
    "        # print(type(inlst),inlst)\n",
    "    print(outlst)\n",
    "    return outlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31ddd61-1b78-466b-bed5-2a278e918d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfz['FPINGTIMES'] = tdfz.PINGTIMES.apply(list2Float,lstsize=4)\n",
    "tdfz[['PTMIN','PTMEAN','PTMAX','PTSD']] = pd.DataFrame(tdfz.FPINGTIMES.tolist(),index = tdfz.index)\n",
    "\n",
    "tdfz['FPINGSTATS'] = tdfz.PINGSTATS.apply(list2Float,lstsize=2)\n",
    "tdfz[['PSCNT','PSLOSS']] = pd.DataFrame(tdfz.FPINGSTATS.tolist(),index = tdfz.index)\n",
    "\n",
    "tdfz['FCELLSIGNAL'] = tdfz.CELLSIGNAL.apply(list2Float,lstsize=3)\n",
    "tdfz[['RSRP','RSRQ','SNR']] = pd.DataFrame(tdfz.FCELLSIGNAL.tolist(),index = tdfz.index)\n",
    "\n",
    "tdfz['FCELLINFO'] = tdfz.CELLINFO.apply(list2Float,lstsize=3)\n",
    "tdfz[['GNB','CID','PCI']] = pd.DataFrame(tdfz.FCELLINFO.tolist(),index = tdfz.index)\n",
    "\n",
    "tdfz['FSPEEDINFO'] = tdfz.SPEEDINFO.apply(list2Float,lstsize=2)\n",
    "tdfz[['DOWNLOAD','UPLOAD']] = pd.DataFrame(tdfz.FSPEEDINFO.tolist(),index = tdfz.index)\n",
    "\n",
    "tdfz['FMAPSIGNAL'] = tdfz.MAPSIGNAL.apply(list2Float,lstsize=3)\n",
    "tdfz[['MRSRP','MRSRQ','MSNR']] = pd.DataFrame(tdfz.FMAPSIGNAL.tolist(),index = tdfz.index)\n",
    "\n",
    "tdfz['FGEOLOC'] = tdfz.GEOLOC.apply(list2Float,lstsize=2)\n",
    "tdfz[['LONGITUDE','LATITUDE']] = pd.DataFrame(tdfz.FGEOLOC.tolist(),index = tdfz.index)\n",
    "\n",
    "tdfz['RSRP'] = tdfz.apply(lambda row: row.RSRP if not np.isnan(row.RSRP) else row.MRSRP,axis=1)\n",
    "tdfz['RSRQ'] = tdfz.apply(lambda row: row.RSRQ if not np.isnan(row.RSRQ) else row.MRSRQ,axis=1)\n",
    "tdfz['SNR'] = tdfz.apply(lambda row: row.SNR if not np.isnan(row.SNR) else row.MSNR,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f902cbe-d62e-46fa-8649-252ff3f664be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumpdf(tdfz.RSRP,head=15)\n",
    "dumpdf(tdfz.RSRQ,head=15)\n",
    "dumpdf(tdfz.SNR,head=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa50bc-c33d-43d3-8590-a0ef3ab05419",
   "metadata": {},
   "outputs": [],
   "source": [
    "keepcol=['GROUP', 'PNGDATE','TEST_UE', 'SCELLID', 'IPERFRCV', 'IPERFSND', 'LONGITUDE','LATITUDE', \n",
    "        'PTMIN', 'PTMEAN', 'PTMAX', 'PTSD', 'PSCNT', 'PSLOSS','RSRP', 'RSRQ', 'SNR',\n",
    "         'GNB', 'CID', 'PCI', 'DOWNLOAD', 'UPLOAD']\n",
    "tdfz = tdfz[keepcol]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b274e7a-b99c-4451-9f31-30c0b209c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumpdf(tdfz,head=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7cbed9-197e-44dc-b870-154355454461",
   "metadata": {},
   "source": [
    "### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2f7aa-e53e-4bf6-a93f-a2d1d9d8d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdfz['geometry'] = pt2geom(tdfz,latcol='LATITUDE',lngcol='LONGITUDE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334fa6bc-6cba-4813-b8c9-3b3e8b3d5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Map Boundaries '''\n",
    "# USA\n",
    "# northern=49.382808 # latitude\n",
    "# southern=24.521208\n",
    "# eastern=-66.945392 # longitude\n",
    "# western=-124.736342\n",
    "fulldict = {\n",
    " 'northwest':[40.434023, -79.966728],\n",
    " 'southeast':[40.408245, -79.944540],\n",
    "}\n",
    "\n",
    "m19dict = {\n",
    "    'northwest':[40.419001, -79.955492],\n",
    "    'southeast':[40.411045, -79.945375]\n",
    "}\n",
    "\n",
    "pointdict = m19dict\n",
    "pointdict['northeast'] = [pointdict['northwest'][0],pointdict['southeast'][1]]\n",
    "pointdict['southwest'] = [pointdict['southeast'][0],pointdict['northwest'][1]]\n",
    "tdfb = pd.DataFrame.from_dict(pointdict,orient='index',columns=['latitude','longitude'])\n",
    "tdfb['geometry'] = pt2geom(tdfb,latcol='latitude',lngcol='longitude')\n",
    "mapgb = df2gp(tdfb.copy())\n",
    "del tdfb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca5ae4-71c0-409b-8c2a-404d773442e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Landmarks '''\n",
    "landmdict = {\n",
    "    \"M19ORU\": [40.414848, -79.948185 ,\"M19ORU\"],\n",
    "    \"PTCORU\": [40.432589473606846, -79.96473135648209,\"PTCORU\"]\n",
    "}\n",
    "tdfb = pd.DataFrame.from_dict(landmdict,orient='index',columns=['latitude','longitude','label'])\n",
    "tdfb['geometry'] = pt2geom(tdfb,latcol='latitude',lngcol='longitude')\n",
    "lmgb = df2gp(tdfb.copy())\n",
    "del tdfb\n",
    "dumpdf(lmgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1e2f6-4d51-4067-bfbb-024719ed3bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgp = df2gp(tdfz.copy()).dropna(subset = ['LATITUDE','LONGITUDE'])\n",
    "tgp = tgp[tgp.LATITUDE < pointdict['northwest'][0]]\n",
    "dumpdf(tgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ee5051-cc02-4070-8065-3347e646a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmgb = lmgb[lmgb.latitude < pointdict['northwest'][0]]\n",
    "dumpdf(lmgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaddcf37-00f6-4720-a47a-bf6e4d0fe6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_plotLabels(fgp2,labelcol=\"label\",ax=None,mapon=True,xoffset=0,yoffset=0, figsize=(30,30), **kwargs):\n",
    "    '''   GeoPandas DataFrame with 'geometry'containing Points '''\n",
    "    if mapon: \n",
    "        fgp2 = fgp2.to_crs(epsg=3857)\n",
    "    if ax is None: \n",
    "        ax = plt.figure().add_subplot(111)\n",
    "    xlst,ylst = getPointXY(fgp2)\n",
    "    # print(f\"x={x}, y={y}\")\n",
    "    for x,y,label in zip(xlst,ylst,fgp2[labelcol]):\n",
    "        ax.text(x+xoffset,y+yoffset,label,**kwargs)\n",
    "    return ax\n",
    "\n",
    "def plotMap(fgp,title=\"NONE\",saveon=False,filename=\"tmp.png\",ax=None):\n",
    "    bbox=dict(facecolor='none', edgecolor='red', boxstyle='round')\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    # ax = gp_plotPoints(mapgb, ax=ax, mapon=True, alpha=0)\n",
    "    ax = gp_plotPoints(fgp,ax=ax, mapon=True, title=title, s=20, c='red',figsize=(25,25))\n",
    "    ax = gp_plotPoints(lmgb,ax=ax, mapon=True,s=20, c='blue')\n",
    "    bbox=dict(facecolor='white', edgecolor='blue', boxstyle='round',alpha=0.75)\n",
    "    ax = gp_plotLabels(lmgb,ax=ax, xoffset = 20,mapon=True,c='blue',fontsize=10,bbox=bbox)\n",
    "    bbox['edgecolor'] = \"red\"\n",
    "    ax = gp_plotLabels(fgp,ax=ax,xoffset=5,labelcol='LABEL',mapon=True,c='red',fontsize=9,rotation=8,bbox=bbox)\n",
    "\n",
    "\n",
    "\n",
    "    if saveon:\n",
    "        savePlot(ax,filename)\n",
    "    return ax\n",
    "try:\n",
    "    del ax\n",
    "except:\n",
    "    pass\n",
    "\n",
    "tgpx = tgp.copy()\n",
    "tgpx['LABEL'] = tgpx.apply(lambda xx: f\"RSRP: {xx.RSRP} SNR: {xx.SNR} PTMEAN: {xx.PTMEAN} DOWNLOAD: {xx.DOWNLOAD} UPLOAD: {xx.UPLOAD}\",axis=1)\n",
    "\n",
    "ax = plotMap(tgpx,title=\"Mill 19 Performance Testing 9/10/24\", filename=\"Mill19-Performance-Testing-2024-09-10.png\",saveon=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e81220-42d7-4401-bd66-090ca2e97c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca174b0-43d7-461b-9ebe-1cbee086add1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
